{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "12a67c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries and specify that graphs should be plotted inline. \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scikitplot as skplt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04de0ea1",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "709c938e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety  class\n",
       "0  vhigh  vhigh     2       2    small    med  unacc\n",
       "1  vhigh  vhigh     2       2    small   high  unacc\n",
       "2  vhigh  vhigh     2       2      med    low  unacc\n",
       "3  vhigh  vhigh     2       2      med    med  unacc\n",
       "4  vhigh  vhigh     2       2      med   high  unacc"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "car_df = pd.read_csv('car.data')\n",
    "columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "car_df.columns = columns\n",
    "car_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eeb70c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buying:  ['vhigh' 'high' 'med' 'low']\n",
      "maint:  ['vhigh' 'high' 'med' 'low']\n",
      "doors:  ['2' '3' '4' '5more']\n",
      "persons:  ['2' '4' 'more']\n",
      "lug_boot:  ['small' 'med' 'big']\n",
      "safety:  ['med' 'high' 'low']\n"
     ]
    }
   ],
   "source": [
    "print(\"buying: \",car_df.buying.unique())\n",
    "print(\"maint: \",car_df.maint.unique())\n",
    "print(\"doors: \",car_df.doors.unique())\n",
    "print(\"persons: \",car_df.persons.unique())\n",
    "print(\"lug_boot: \",car_df.lug_boot.unique())\n",
    "print(\"safety: \",car_df.safety.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c86bba47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying      0\n",
       "maint       0\n",
       "doors       0\n",
       "persons     0\n",
       "lug_boot    0\n",
       "safety      0\n",
       "class       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing value\n",
    "car_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d61febf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "acc       384\n",
       "good       69\n",
       "unacc    1209\n",
       "vgood      65\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there is imbalanced data\n",
    "car_df.groupby('class')['class'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee8f3c4",
   "metadata": {},
   "source": [
    "## Transform ordinal features into categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5c1322",
   "metadata": {},
   "source": [
    "Pros: Treating them as categories avoids making the assumption of a linear relationship between categories(such as integer mapping), ensuring that the model captures the true nature of the ordinal variable. Moreover, it preserves this inherent ordinal information, allowing the model to capture the relationship between categories based on their order.\n",
    "\n",
    "Cons: Increased dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dc86fe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dependent and independent variables\n",
    "x = car_df.iloc[:,:6]\n",
    "y = car_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1b94ef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  treat ordinal variables as categorical\n",
    "nominal_features = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']\n",
    "x = pd.get_dummies(x, columns=nominal_features, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54759536",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "926db9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for inner and outer loops\n",
    "i = 42\n",
    "inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "score = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "38537742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desicion tree\n",
    "\n",
    "# Tuning hyperparameters\n",
    "criterions = ['gini', 'entropy']\n",
    "d_rng =  list(range(1,10)) # max_depth\n",
    "s_rng = list(range(2,10)) # min_samples_split\n",
    "t_grid = dict(criterion = criterions,max_depth = d_rng,min_samples_split = s_rng)\n",
    "\n",
    "# model\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# non-nested parameter search and scoring\n",
    "tree_clf = GridSearchCV(tree, t_grid, cv=inner_cv, scoring='accuracy')\n",
    "\n",
    "# nested CV with parameter opitimization\n",
    "tree_score = cross_val_score(tree_clf,X=x,y=y, cv=outer_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e6e25a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn\n",
    "\n",
    "# Tuning hyperparameters\n",
    "weights = ['uniform', 'distance']\n",
    "k_values = list(range(1,30))\n",
    "k_grid = dict(weights = weights,n_neighbors = k_values)\n",
    "\n",
    "# model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# non-nested parameter search and scoring\n",
    "knn_clf = GridSearchCV(knn, k_grid, cv=inner_cv, scoring='accuracy')\n",
    "\n",
    "# nested CV with parameter opitimization\n",
    "knn_score = cross_val_score(knn_clf,X=x,y=y, cv=outer_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "139789a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "\n",
    "# Tuning hyperparameters\n",
    "penalty = ['l1', 'l2', 'elasticnet']\n",
    "c_values = [10**i for i in range(-5,9)]\n",
    "l_grid = dict(penalty = penalty, C = c_values)\n",
    "\n",
    "# model\n",
    "lg = LogisticRegression()\n",
    "\n",
    "# non-nested parameter search and scoring\n",
    "lg_clf = GridSearchCV(lg, l_grid, cv = inner_cv, scoring = 'accuracy')\n",
    "\n",
    "# nested CV with parameter opitimization\n",
    "lg_score = cross_val_score(lg_clf, X=x, y=y, cv=outer_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "55ca5925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm\n",
    "# Tuning hyper-parameter\n",
    "g = [0.001, 0.01, 0.1, 1, 10, 100] # gamma\n",
    "c = [0.1, 1, 10, 100]\n",
    "s_grid = dict(C = c, gamma = g )\n",
    "\n",
    "# model\n",
    "svm = SVC(probability = True)\n",
    "\n",
    "# non-nested parameter search and scoring\n",
    "svm_clf = GridSearchCV(svm, s_grid, cv=inner_cv, scoring='accuracy')\n",
    "\n",
    "# nested CV with parameter opitimization\n",
    "svm_score = cross_val_score(svm_clf,X=x,y=y, cv=outer_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dd139ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Decision Tree': 0.9096711996218958,\n",
       " 'KNN': 0.8256879994844032,\n",
       " 'Logistic Regression': 0.9305085610552548,\n",
       " 'SVM': 0.9947889812666495}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = {}\n",
    "score['Decision Tree'] = tree_score.mean()\n",
    "score['KNN'] = knn_score.mean()\n",
    "score['Logistic Regression'] = lg_score.mean()\n",
    "score['SVM'] = svm_score.mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cbc379",
   "metadata": {},
   "source": [
    "## Transform ordinal features into numeric "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e14c8fd",
   "metadata": {},
   "source": [
    "Pros: It simplifies the data preprocessing step as you don't need to create additional dummy variables.\n",
    "\n",
    "Cons: Treating ordinal variables as numeric assumes that the intervals between the categories are equal, which may not be the case in reality. This assumption can lead to incorrect interpretations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a5418dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "car_df = pd.read_csv('car.data')\n",
    "columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "car_df.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "26fd7b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dependent and independent variables\n",
    "x = car_df.iloc[:,:6]\n",
    "y = car_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3f6437cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# treat ordinal variables as numeric\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for column in x.columns:\n",
    "    x[column] = label_encoder.fit_transform(x[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3319ff",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "55f6d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for inner and outer loops\n",
    "i = 42\n",
    "inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "score = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1325aff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desicion tree\n",
    "\n",
    "# Tuning hyperparameters\n",
    "criterions = ['gini', 'entropy']\n",
    "d_rng =  list(range(1,10)) # max_depth\n",
    "s_rng = list(range(2,10)) # min_samples_split\n",
    "t_grid = dict(criterion = criterions,max_depth = d_rng,min_samples_split = s_rng)\n",
    "\n",
    "# model\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# non-nested parameter search and scoring\n",
    "tree_clf = GridSearchCV(tree, t_grid, cv=inner_cv, scoring='accuracy')\n",
    "\n",
    "# nested CV with parameter opitimization\n",
    "tree_score = cross_val_score(tree_clf,X=x,y=y, cv=outer_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "98aeb665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn\n",
    "\n",
    "# Tuning hyperparameters\n",
    "weights = ['uniform', 'distance']\n",
    "k_values = list(range(1,30))\n",
    "k_grid = dict(weights = weights,n_neighbors = k_values)\n",
    "\n",
    "# model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# non-nested parameter search and scoring\n",
    "knn_clf = GridSearchCV(knn, k_grid, cv=inner_cv, scoring='accuracy')\n",
    "\n",
    "# nested CV with parameter opitimization\n",
    "knn_score = cross_val_score(knn_clf,X=x,y=y, cv=outer_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2c906fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "\n",
    "# Tuning hyperparameters\n",
    "penalty = ['l1', 'l2', 'elasticnet']\n",
    "c_values = [10**i for i in range(-5,9)]\n",
    "l_grid = dict(penalty = penalty, C = c_values)\n",
    "\n",
    "# model\n",
    "lg = LogisticRegression()\n",
    "\n",
    "# non-nested parameter search and scoring\n",
    "lg_clf = GridSearchCV(lg, l_grid, cv = inner_cv, scoring = 'accuracy')\n",
    "\n",
    "# nested CV with parameter opitimization\n",
    "lg_score = cross_val_score(lg_clf, X=x, y=y, cv=outer_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "990d91b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm\n",
    "# Tuning hyper-parameter\n",
    "g = [0.001, 0.01, 0.1, 1, 10, 100] # gamma\n",
    "c = [0.1, 1, 10, 100]\n",
    "s_grid = dict(C = c, gamma = g )\n",
    "\n",
    "# model\n",
    "svm = SVC(probability = True)\n",
    "\n",
    "# non-nested parameter search and scoring\n",
    "svm_clf = GridSearchCV(svm, s_grid, cv=inner_cv, scoring='accuracy')\n",
    "\n",
    "# nested CV with parameter opitimization\n",
    "svm_score = cross_val_score(svm_clf,X=x,y=y, cv=outer_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d8cf6ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Decision Tree': 0.9490364784738334,\n",
       " 'KNN': 0.9044736078886311,\n",
       " 'Logistic Regression': 0.704673133109908,\n",
       " 'SVM': 0.9907353699407064}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = {}\n",
    "score['Decision Tree'] = tree_score.mean()\n",
    "score['KNN'] = knn_score.mean()\n",
    "score['Logistic Regression'] = lg_score.mean()\n",
    "score['SVM'] = svm_score.mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad6a8b",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361ce3f1",
   "metadata": {},
   "source": [
    "Considering that SVM has the highest accuracy (0.9948), it appears to be the best-performing model on this dataset based on the cross validation mean accuracy scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9a4f378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "car_df = pd.read_csv('car.data')\n",
    "columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "car_df.columns = columns\n",
    "\n",
    "# define dependent and independent variables\n",
    "x = car_df.iloc[:,:6]\n",
    "y = car_df['class']\n",
    "\n",
    "#  treat ordinal variables as categorical\n",
    "nominal_features = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']\n",
    "x = pd.get_dummies(x, columns=nominal_features, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "66ef9edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training(70%) and testing(30%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9ca7a3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning hyper-parameter\n",
    "g = [0.001, 0.01, 0.1, 1, 10, 100] # gamma\n",
    "c = [0.1, 1, 10, 100]\n",
    "s_grid = dict(C = c, gamma = g )\n",
    "\n",
    "# model\n",
    "svm = SVC(probability = True)\n",
    "\n",
    "# hyper-parameter search and scoring\n",
    "svm_clf = GridSearchCV(svm, s_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "#fit the model\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred = svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "aa7c0b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'C': 100, 'gamma': 0.1}\n",
      "best score:  0.9842735159973938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       1.00      0.98      0.99       123\n",
      "        good       1.00      1.00      1.00        22\n",
      "       unacc       0.99      1.00      1.00       354\n",
      "       vgood       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00       519\n",
      "   macro avg       1.00      1.00      1.00       519\n",
      "weighted avg       1.00      1.00      1.00       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('best params: ', svm_clf.best_params_)\n",
    "print('best score: ', svm_clf.best_score_)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15adb6f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In conclusion, the Support Vector Machine (SVM) model, optimized with hyperparameters C=100 and gamma=0.1, has demonstrated exceptional performance in classifying the dataset. The model achieved an impressive accuracy of 100%, indicating its robustness in accurately predicting class labels. Furthermore, the precision, recall, and F1-scores for all classes are consistently high, underscoring the model's reliability in handling different categories. With minimal misclassifications and strong overall performance, this SVM model is a compelling choice for this classification task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
